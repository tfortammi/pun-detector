{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GRUBsfYZJDu2"
   },
   "source": [
    "# Dappity Dap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmCZLMFXK__x"
   },
   "source": [
    "### Characteristics of Puns\n",
    "* Converging Meanings \n",
    "* Sound \n",
    "* Association\n",
    "\n",
    "_Things to try:_\n",
    "* split words by sound / parsing to increase accuracy of converging meanings hypothesis\n",
    "    -  e.g. \"The soundtrack for Blackfish was **orca**strated.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lriPsNERLdhM"
   },
   "source": [
    "### Target: Converging Meanings\n",
    "\n",
    "We have observed that puns often make use of words that have very similar meanings. For example:\n",
    "\n",
    "'He said I was **average** - but he was just being **mean**.'\n",
    "\n",
    "where 'average' and 'mean' have the same meanings but are expressed differently. \n",
    "\n",
    "___\n",
    "\n",
    "In order to test this, we will do the following:\n",
    "\n",
    "* Step 1: Use Synset to list synonyms of tokens\n",
    "* Step 2: Find common words in Synsets within a sentence\n",
    "* Step 3: Determine correlation between converging meanings & whether a sentence is a pun or not\n",
    "\n",
    "---\n",
    "\n",
    "Import/Download relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7764,
     "status": "ok",
     "timestamp": 1547691068307,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "a2yw0bHqtbkE",
    "outputId": "9fa969c9-6caa-4698-b990-dc573e142d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\WaThone\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from textblob import Word\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uCfLoO_cNw19"
   },
   "source": [
    "For this method, we will use NLTK's WordNet corpus to find the synsets of each token in a sentence.\n",
    "\n",
    "As an example, let's test it out on the word **'plant'** first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9532,
     "status": "ok",
     "timestamp": 1547691070459,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "pK56tdcLLVxl",
    "outputId": "eaf3f0df-e96d-4ea4-c729-d18f91b301c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Case  0\n",
      "Synset('plant.n.01')\n",
      "buildings for carrying on industrial labor\n",
      "['plant', 'works', 'industrial_plant']\n",
      " \n",
      "Use Case  1\n",
      "Synset('plant.n.02')\n",
      "(botany) a living organism lacking the power of locomotion\n",
      "['plant', 'flora', 'plant_life']\n",
      " \n",
      "Use Case  2\n",
      "Synset('plant.n.03')\n",
      "an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience\n",
      "['plant']\n",
      " \n"
     ]
    }
   ],
   "source": [
    "word = Word('plant')\n",
    "for i in range(3):\n",
    "    print('Use Case ', i)\n",
    "    print(word.synsets[i])\n",
    "    print(word.definitions[i])\n",
    "    print(word.synsets[i].lemma_names())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-hvCZaYRvymW"
   },
   "source": [
    "Through WordNet, the **use cases** (Synsets) of the word \"Plant\" can be found, as well as the **definitions** and **Synonyms** (Lemma Names) as the input.\n",
    "\n",
    "---\n",
    "        \n",
    "           \n",
    "Let's first eyeball how relevant the lemmas of each significant word in a sentence to determining if a sentence is a pun. \n",
    "\n",
    "**The example we will use is: \"The past, the present and the future walked into a bar. It was tense.\"**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10089,
     "status": "ok",
     "timestamp": 1547691071514,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "aMjxEEmJOyLw",
    "outputId": "059c75ae-4f62-4862-b09b-63ed1032c719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\WaThone\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\WaThone\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# First, importing relevant packages, etc\n",
    "\n",
    "import codecs\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import PunktSentenceTokenizer,sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lxir3NmAx4Zf"
   },
   "source": [
    "We'll need to process the sentence, which includes lemmatizing, filtering out stop words, stripping punctuation and tokenizing the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1511
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9733,
     "status": "ok",
     "timestamp": 1547691071516,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "FTK9plVwOSiN",
    "outputId": "eca71be4-0d24-45c1-c560-ffd682bb3bbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered word: 'The' and its lemmas:\n",
      "\n",
      "Filtered word: 'past' and its lemmas:\n",
      "['past', 'past_times', 'yesteryear']\n",
      "['past']\n",
      "['past', 'past_tense']\n",
      "['past']\n",
      "['past', 'preceding', 'retiring']\n",
      "['by', 'past']\n",
      "\n",
      "Filtered word: 'present' and its lemmas:\n",
      "['present', 'nowadays']\n",
      "['present']\n",
      "['present', 'present_tense']\n",
      "['show', 'demo', 'exhibit', 'present', 'demonstrate']\n",
      "['present', 'represent', 'lay_out']\n",
      "['stage', 'present', 'represent']\n",
      "['present', 'submit']\n",
      "['present', 'pose']\n",
      "['award', 'present']\n",
      "['give', 'gift', 'present']\n",
      "['deliver', 'present']\n",
      "['introduce', 'present', 'acquaint']\n",
      "['portray', 'present']\n",
      "['confront', 'face', 'present']\n",
      "['present']\n",
      "['salute', 'present']\n",
      "['present']\n",
      "['present']\n",
      "\n",
      "Filtered word: 'future' and its lemmas:\n",
      "['future', 'hereafter', 'futurity', 'time_to_come']\n",
      "['future', 'future_tense']\n",
      "['future']\n",
      "['future']\n",
      "['future']\n",
      "['future', 'next', 'succeeding']\n",
      "['future']\n",
      "\n",
      "Filtered word: 'walked' and its lemmas:\n",
      "['walk']\n",
      "['walk']\n",
      "['walk']\n",
      "['walk']\n",
      "['walk']\n",
      "['walk']\n",
      "['walk']\n",
      "['walk']\n",
      "['walk']\n",
      "['walk', 'take_the_air']\n",
      "\n",
      "Filtered word: 'bar' and its lemmas:\n",
      "['barroom', 'bar', 'saloon', 'ginmill', 'taproom']\n",
      "['bar']\n",
      "['bar']\n",
      "['measure', 'bar']\n",
      "['bar']\n",
      "['prevention', 'bar']\n",
      "['bar']\n",
      "['bar']\n",
      "['legal_profession', 'bar', 'legal_community']\n",
      "['stripe', 'streak', 'bar']\n",
      "['cake', 'bar']\n",
      "['Browning_automatic_rifle', 'BAR']\n",
      "['bar']\n",
      "['bar']\n",
      "['bar']\n",
      "['bar', 'debar', 'exclude']\n",
      "['barricade', 'block', 'blockade', 'stop', 'block_off', 'block_up', 'bar']\n",
      "['banish', 'relegate', 'bar']\n",
      "['bar']\n",
      "\n",
      "Filtered word: 'It' and its lemmas:\n",
      "['information_technology', 'IT']\n",
      "\n",
      "Filtered word: 'tense' and its lemmas:\n",
      "['tense']\n",
      "['strain', 'tense']\n",
      "['tense']\n",
      "['tense', 'tense_up']\n",
      "['tense', 'strain', 'tense_up']\n",
      "['tense']\n",
      "['tense']\n",
      "['tense']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def simpleFilter(sentence):\n",
    "    \n",
    "    '''This function filters out stopwords, lemmatizes, tokenizes, and \n",
    "    strips punctuation from the input sentence and returns the a list of \n",
    "    filtered tokens'''\n",
    "    \n",
    "    filtered_sent = []\n",
    "    \n",
    "    # Strip punctuation\n",
    "    stripped = re.sub(\"[(.)',=!#@]\", '', sentence)\n",
    "        \n",
    "    # filter out stopwords \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Tokenize\n",
    "    words = word_tokenize(stripped)\n",
    "    \n",
    "    # Lemmatize and Filter out Stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(lemmatizer.lemmatize(w))\n",
    "\n",
    "    return filtered_sent\n",
    "  \n",
    "def printLemmas(word):\n",
    "    \n",
    "    '''This function prints out all synonyms of a given word.'''\n",
    "    \n",
    "    for ss in Word(word).synsets:\n",
    "        print(ss.lemma_names())\n",
    "        \n",
    "\n",
    "# Print \n",
    "\n",
    "s = 'The past, the present and the future walked into a bar. It was tense.'\n",
    "\n",
    "for word in simpleFilter(s):\n",
    "    print(\"Filtered word: '\" + word + \"' and its lemmas:\")\n",
    "    printLemmas(word)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lxl_W9dEvRWZ"
   },
   "source": [
    "---\n",
    "## **Hypothesis 1: Converging Meaning Pun**\n",
    "\n",
    "We observe that the word 'tense' appears as a synonym of the words 'present', 'past', and 'future'. Since we are exploring puns with converging meanings, **we hypothesise that we are more likely to find words with converging meanings in puns than in non-puns.**\n",
    "\n",
    "---\n",
    "\n",
    "To do this, we first produce a list of unique synonyms of a certain word, excluding the word itself.\n",
    "\n",
    "\n",
    "Let's try this on the word \"plant\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9349,
     "status": "ok",
     "timestamp": 1547691071518,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "GZrNVNuoQmdK",
    "outputId": "b797c570-88cb-4d20-9b47-ab1f2415ecec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['works', 'industrial_plant', 'flora', 'plant_life', 'set', 'implant', 'engraft', 'embed', 'imbed', 'establish', 'found', 'constitute', 'institute']\n"
     ]
    }
   ],
   "source": [
    "def create_lemmas(word):\n",
    "    lemmas_list = []\n",
    "    for ss in Word(word).synsets:\n",
    "        lemmas_list.append(ss.lemma_names())\n",
    "    return lemmas_list\n",
    "\n",
    "def process_lemmas(lemmas_list, word):\n",
    "    '''\n",
    "    This function process the lemma list of all the definition of a word\n",
    "    and returns a list of all associated unrepeated words with the word\n",
    "    '''\n",
    "    all_lemmas = []\n",
    "    for each_list in lemmas_list:\n",
    "        for lemma in each_list:\n",
    "            if lemma != word and lemma not in all_lemmas:\n",
    "                all_lemmas.append(lemma)\n",
    "    return all_lemmas\n",
    "\n",
    "\n",
    "print(process_lemmas(create_lemmas('plant'), 'plant'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7PhQGRD4XEU"
   },
   "source": [
    "Next, we have to find out if synonyms of any word in a sentence can be found in the rest of the sentence, and count the number of times this occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8961,
     "status": "ok",
     "timestamp": 1547691071518,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "coVT022UOrwf",
    "outputId": "c01cf41c-bdb6-43cd-c110-d85293aab5c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past tense\n",
      "present tense\n",
      "future tense\n",
      "The number of synonym pairs in this sentence is 3\n"
     ]
    }
   ],
   "source": [
    "def common_syn(s):\n",
    "    \n",
    "    '''\n",
    "    This function takes in a sentence, processes and tokenizes it and\n",
    "    prints each significant word and tests if its synonyms can be found\n",
    "    in the rest of the sentence. It prints the pair and returns the\n",
    "    number of pairs found.\n",
    "    '''\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    # Filter the sentence to remove filler words / stopwords\n",
    "    filtered_words = simpleFilter(s)\n",
    "    \n",
    "    for index, word in enumerate(filtered_words):\n",
    "        if word.isalpha():\n",
    "            lemma_list_of_term = process_lemmas(create_lemmas(word),word)\n",
    "\n",
    "            # test if any word in the rest of the sentence appears in the lemma list of current word\n",
    "            for other_word in filtered_words[index+1:]:\n",
    "                if other_word in ' '.join(lemma_list_of_term):\n",
    "                    count += 1\n",
    "                    print(word, other_word)\n",
    "    return count\n",
    "    \n",
    "    \n",
    "s = 'The past, the present and the future walked into a bar. It was tense.'\n",
    "print('The number of synonym pairs in this sentence is',common_syn(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9rXRmeVvyfbo"
   },
   "source": [
    "In order to see if this method does work, we will test it out on our list of pre-tagged puns and non-puns where puns are tagged '0' and non-puns are tagged '1'\n",
    "\n",
    "We import the list and apply our function common_syn to it, under the label 'Syn Count'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2178
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1614,
     "status": "ok",
     "timestamp": 1547691113200,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "SDLtb-6fXKWr",
    "outputId": "0a927665-4991-44d3-fb5a-caa2d70a0d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuna fish\n",
      "I le\n",
      "bigger le\n",
      "bed le\n",
      "I le\n",
      "pirate high\n",
      "pirate sea\n",
      "make hit\n",
      "I one\n",
      "Going sound\n",
      "bed sleep\n",
      "After ate\n",
      "said ate\n",
      "turned around\n",
      "broke leg\n",
      "I one\n",
      "got one\n",
      "cannibal eat\n",
      "got make\n",
      "paid make\n",
      "reversing back\n",
      "I one\n",
      "got one\n",
      "got back\n",
      "one I\n",
      "go work\n",
      "Cheap u\n",
      "Thrills u\n",
      "want u\n",
      "post office\n",
      "wear wear\n",
      "look see\n",
      "whistle whistle\n",
      "mad hare\n",
      "Old go\n",
      "die go\n",
      "back second\n",
      "call phone\n",
      "Cell phone\n",
      "mean egg\n",
      "laying egg\n",
      "I number\n",
      "people wash\n",
      "little light\n",
      "seems see\n",
      "door door\n",
      "take make\n",
      "fly fly\n",
      "like like\n",
      "metal met\n",
      "I 5\n",
      "mean end\n",
      "went low\n",
      "wardrobe closet\n",
      "one I\n",
      "punch punch\n",
      "went last\n",
      "Do get\n",
      "know get\n",
      "broth stock\n",
      "cat sick\n",
      "cheese cheese\n",
      "Buffalo Bison\n",
      "Make one\n",
      "call one\n",
      "right -\n",
      "duck put\n",
      "Thieves steal\n",
      "dentist tooth\n",
      "theatrical performance\n",
      "pun play\n",
      "pun word\n",
      "play word\n",
      "average mean\n",
      "In I\n",
      "past tense\n",
      "present tense\n",
      "future tense\n",
      "soda soda\n",
      "running go\n",
      "Better go\n",
      "present tense\n",
      "past tense\n",
      "saw ad\n",
      "happens come\n",
      "Id I\n",
      "Id I\n",
      "know get\n",
      "alarm clock\n",
      "Have eat\n",
      "ever time\n",
      "tried time\n",
      "clock time\n",
      "take make\n",
      "seasoned veteran\n",
      "remember back\n",
      "boomerang back\n",
      "sign language\n",
      "I atom\n",
      "error error\n",
      "error one\n",
      "error one\n",
      "noble man\n",
      "fellow man\n",
      "first first\n",
      "first first\n",
      "first first\n",
      "Two I\n",
      "wood le\n",
      "I one\n",
      "I le\n",
      "took le\n",
      "one le\n",
      "Or go\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>P/NP</th>\n",
       "      <th>Syn Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can tune a guitar, but you can't tuna fish...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two peanuts were walking in a tough neighborho...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If I buy a bigger bed will I have more or less...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The earth's rotation really makes my day.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I told my friend she drew her eyebrows too hig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  P/NP  Syn Count\n",
       "0  You can tune a guitar, but you can't tuna fish...     0          1\n",
       "1  Two peanuts were walking in a tough neighborho...     0          0\n",
       "2  If I buy a bigger bed will I have more or less...     0          4\n",
       "3          The earth's rotation really makes my day.     0          0\n",
       "4  I told my friend she drew her eyebrows too hig...     0          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('puns_final.csv', encoding='latin-1')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "df['Syn Count'] = df['Sentence'].apply(common_syn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UKVUEdxK6b1o"
   },
   "source": [
    "To find out if this method is accurate, we use the correlation between whether the sentence is a pun or not and the Syn Count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 963,
     "status": "ok",
     "timestamp": 1547691120198,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "laC4Fb4QYmF2",
    "outputId": "e1e20d28-0bec-4945-f4a2-894b8f7e746b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P/NP</th>\n",
       "      <th>Syn Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P/NP</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Syn Count</th>\n",
       "      <td>0.062171</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               P/NP  Syn Count\n",
       "P/NP       1.000000   0.062171\n",
       "Syn Count  0.062171   1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S-9IxQXp6pIP"
   },
   "source": [
    "In this case, it appears the Syn Count is not very highly correlated with whether the sentence is a pun or not...\n",
    "\n",
    "Perhaps we should try a different approach.\n",
    "\n",
    "---\n",
    "\n",
    "Other than the ability to find synonyms, WordNet can also find out a range of other details about a word.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lxCPM76im7dv"
   },
   "source": [
    "The functions below make use of WordNet to yield synonyms, hyponyms, antonyms, words that are similar to as well as words that the WordNet corpus has recorded as \"also sees\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnkjHc1Kb6aI"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def get_all_synsets(word, pos=None):\n",
    "    for ss in wn.synsets(word):\n",
    "        for lemma in ss.lemma_names():\n",
    "            yield (lemma, ss.name())\n",
    "\n",
    "\n",
    "def get_all_hyponyms(word, pos=None):\n",
    "    for ss in wn.synsets(word, pos=pos):\n",
    "            for hyp in ss.hyponyms():\n",
    "                for lemma in hyp.lemma_names():\n",
    "                    yield (lemma, hyp.name())\n",
    "\n",
    "\n",
    "def get_all_similar_tos(word, pos=None):\n",
    "    for ss in wn.synsets(word):\n",
    "            for sim in ss.similar_tos():\n",
    "                for lemma in sim.lemma_names():\n",
    "                    yield (lemma, sim.name())\n",
    "\n",
    "\n",
    "def get_all_antonyms(word, pos=None):\n",
    "    for ss in wn.synsets(word, pos=None):\n",
    "        for sslema in ss.lemmas():\n",
    "            for antlemma in sslema.antonyms():\n",
    "                    yield (antlemma.name(), antlemma.synset().name())\n",
    "\n",
    "\n",
    "def get_all_also_sees(word, pos=None):\n",
    "        for ss in wn.synsets(word):\n",
    "            for also in ss.also_sees():\n",
    "                for lemma in also.lemma_names():\n",
    "                    yield (lemma, also.name())\n",
    "\n",
    "\n",
    "def get_all_synonyms(word, pos=None):\n",
    "    for x in get_all_synsets(word, pos):\n",
    "        yield (x[0], x[1], 'ss')\n",
    "    for x in get_all_hyponyms(word, pos):\n",
    "        yield (x[0], x[1], 'hyp')\n",
    "    for x in get_all_similar_tos(word, pos):\n",
    "        yield (x[0], x[1], 'sim')\n",
    "    for x in get_all_antonyms(word, pos):\n",
    "        yield (x[0], x[1], 'ant')\n",
    "    for x in get_all_also_sees(word, pos):\n",
    "        yield (x[0], x[1], 'also')\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "crXdzXjP-HKv"
   },
   "source": [
    "Let's use the words 'happy' and 'cutlery' to see what kind of details WordNet can figure out about a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 832
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 767,
     "status": "ok",
     "timestamp": 1547691130641,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "XBq094Cc8U0W",
    "outputId": "2b6905b9-f382-450a-94bf-9eac684da3e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are synonyms of 'happy':\n",
      "('happy', 'happy.a.01')\n",
      "('felicitous', 'felicitous.s.02')\n",
      "('happy', 'felicitous.s.02')\n",
      "('glad', 'glad.s.02')\n",
      "('happy', 'glad.s.02')\n",
      "('happy', 'happy.s.04')\n",
      "('well-chosen', 'happy.s.04')\n",
      "\n",
      "The following are hyponyms (words that are more specific) of 'cutlery':\n",
      "('bolt_cutter', 'bolt_cutter.n.01')\n",
      "('cigar_cutter', 'cigar_cutter.n.01')\n",
      "('die', 'die.n.03')\n",
      "('edge_tool', 'edge_tool.n.01')\n",
      "('glass_cutter', 'glass_cutter.n.03')\n",
      "('tile_cutter', 'tile_cutter.n.01')\n",
      "('fork', 'fork.n.01')\n",
      "('spoon', 'spoon.n.01')\n",
      "('Spork', 'spork.n.01')\n",
      "('table_knife', 'table_knife.n.01')\n",
      "\n",
      "The following are similar to 'happy':\n",
      "('blessed', 'blessed.s.06')\n",
      "('blissful', 'blissful.s.01')\n",
      "('bright', 'bright.s.09')\n",
      "('golden', 'golden.s.02')\n",
      "('halcyon', 'golden.s.02')\n",
      "('prosperous', 'golden.s.02')\n",
      "('laughing', 'laughing.s.01')\n",
      "('riant', 'laughing.s.01')\n",
      "('fortunate', 'fortunate.a.01')\n",
      "('willing', 'willing.a.01')\n",
      "('felicitous', 'felicitous.a.01')\n",
      "\n",
      "The following are antonyms (opposite) of 'happy':\n",
      "('unhappy', 'unhappy.a.01')\n",
      "\n",
      "The following are words that should also be seen with 'happy':\n",
      "('cheerful', 'cheerful.a.01')\n",
      "('contented', 'contented.a.01')\n",
      "('content', 'contented.a.01')\n",
      "('elated', 'elated.a.01')\n",
      "('euphoric', 'euphoric.a.01')\n",
      "('felicitous', 'felicitous.a.01')\n",
      "('glad', 'glad.a.01')\n",
      "('joyful', 'joyful.a.01')\n",
      "('joyous', 'joyous.a.01')\n"
     ]
    }
   ],
   "source": [
    "print(\"The following are synonyms of 'happy':\")\n",
    "for x in get_all_synsets('happy'):\n",
    "    print(x)\n",
    "print()\n",
    "print(\"The following are hyponyms (words that are more specific) of 'cutlery':\")\n",
    "for x in get_all_hyponyms('cutlery'):\n",
    "    print(x)\n",
    "print()\n",
    "print(\"The following are similar to 'happy':\")\n",
    "for x in get_all_similar_tos('happy'):\n",
    "    print(x)\n",
    "print()\n",
    "print(\"The following are antonyms (opposite) of 'happy':\")\n",
    "for x in get_all_antonyms('happy'):\n",
    "    print(x)\n",
    "print()\n",
    "print(\"The following are words that should also be seen with 'happy':\")\n",
    "for x in get_all_also_sees('happy'):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2mBXMIL-R8z"
   },
   "source": [
    "Let's all the categories above words that are **related** to the main word. \n",
    "\n",
    "Now, we want to do the same as we did for the synonym count and define some functions that will find the common related words - not just within the sentence, but also with the related words of the other words in the sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3wnzCQ5gRjO"
   },
   "outputs": [],
   "source": [
    "def related_list(word):\n",
    "    lemma_list = []\n",
    "    for x in get_all_synonyms(word):\n",
    "        lemma_list.append(x)\n",
    "    return list(set(lemma_list))\n",
    "\n",
    "def common_related(s):\n",
    "    filtered = simpleFilter(s)\n",
    "    count = 0\n",
    "    for index, word in enumerate(filtered):\n",
    "        related = related_list(word)\n",
    "        for r_set in related:\n",
    "            if r_set[0] in filtered[index+1:]:\n",
    "                count += 1\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0snqjLX-lKD-"
   },
   "source": [
    "**Example:**\n",
    "\n",
    "'What do you call a belt with a watch on it? A waist of time.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 804,
     "status": "ok",
     "timestamp": 1547695763249,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "h17Biokqk0QQ",
    "outputId": "d1c3359a-3d58-41b7-853b-36a960171cd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: What do you call a belt with a watch on it? A waist of time.\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "Number of Related pairs: 0\n"
     ]
    }
   ],
   "source": [
    "s = 'What do you call a belt with a watch on it? A waist of time.'\n",
    "\n",
    "filtered = simpleFilter(s)\n",
    "count = 0\n",
    "print('Sentence:',s)\n",
    "print('-----' *10)\n",
    "print()\n",
    "for index, word in enumerate(filtered):\n",
    "    related = related_list(word)\n",
    "    for r_set in related:\n",
    "        if r_set[0] in filtered[index+1:]:\n",
    "            print(\"The word '\" + word + \"' in the sentence is related to '\" + r_set[0] + \"' as\", r_set, \"to mean '\" + wordnet.synset(r_set[1]).definition() +\"'\")\n",
    "            print()\n",
    "            count += 1\n",
    "print('-----' * 10)\n",
    "print('Number of Related pairs:', count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3k1fliJg2XnI"
   },
   "source": [
    "Now we want to apply this to the rest of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1620,
     "status": "ok",
     "timestamp": 1547705575618,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "T9mz_g5plIsT",
    "outputId": "0d8a5758-a08d-4c76-f719-ca5363add87e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>P/NP</th>\n",
       "      <th>Syn Count</th>\n",
       "      <th>Length</th>\n",
       "      <th>Related Count</th>\n",
       "      <th>Rel Count / Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Can February March? No, but April May.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>He said I was average - but he was just being ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>If you want something you never had, you have ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>How does a penguin build itÂs house? Igloos i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Smaller babies may be delivered by stork but t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  P/NP  Syn Count  \\\n",
       "128             Can February March? No, but April May.     0          0   \n",
       "192  He said I was average - but he was just being ...     0          1   \n",
       "275  If you want something you never had, you have ...     1          0   \n",
       "125  How does a penguin build itÂs house? Igloos i...     0          0   \n",
       "32   Smaller babies may be delivered by stork but t...     0          0   \n",
       "\n",
       "     Length  Related Count  Rel Count / Len  \n",
       "128      38              0         0.000000  \n",
       "192      51              2         0.039216  \n",
       "275      83              2         0.024096  \n",
       "125      57              0         0.000000  \n",
       "32       75              0         0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Length'] = df['Sentence'].apply(len) #added this because it's mysteriously missing, but need to filter the length next time\n",
    "df['Related Count'] = df['Sentence'].apply(common_related)\n",
    "df['Rel Count / Len'] = df['Related Count'] / df['Length']\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uldmmxd4hc_N"
   },
   "source": [
    "Here is a description of the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 744,
     "status": "error",
     "timestamp": 1547709021329,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "QQS8AyWghNb9",
    "outputId": "86b37909-702c-47ea-c222-85e89c1157fd"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'histfit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3fc0ab03d666>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Related Count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'histfit'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.describe()\n",
    "\n",
    "r = df['Related Count']\n",
    "plt.histfit(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V9sgFr4Mgi1K"
   },
   "source": [
    "The code below finds the correlation between the different variables in the data frame. \n",
    "\n",
    "As can be seen, the correlation between whether a sentence is a pun or not and the number of related count pairs is debatable.\n",
    "\n",
    "We also took related count / len of sentence as a longer sentence is more likely to have more related pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 769,
     "status": "ok",
     "timestamp": 1547706932909,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "SDFQNmnfmD1L",
    "outputId": "05687ff5-75b4-4c40-af74-81acd1738477"
   },
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fWL8jgk9niVV"
   },
   "source": [
    "We'll try to turn this correlation into an actionable \"algorithm\" to predict if a sentence is a pun or not. \n",
    "\n",
    "The following is another data set with 60 puns and 100 non-puns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 765,
     "status": "ok",
     "timestamp": 1547698642916,
     "user": {
      "displayName": "Tammi Chng",
      "photoUrl": "",
      "userId": "04092419009882397415"
     },
     "user_tz": -480
    },
    "id": "RmFYXOdxLX6g",
    "outputId": "5f85d643-dee9-45dc-d2d3-716b6947d3ae"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('puns_test.csv')\n",
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYPxIGisoGaJ"
   },
   "source": [
    "Let's now code the \"algorithm\".'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rvTt7mDroSvV"
   },
   "outputs": [],
   "source": [
    "common_related(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lriPsNERLdhM"
   },
   "source": [
    "### Target: Similar Sounds\n",
    "\n",
    "Other puns involve usage of homophones, words with similar sound but different meanings. For example:\n",
    "\n",
    "'The **pony** had a **raspy** voice. It was **hoarse**.'\n",
    "\n",
    "where 'hoarse' means the same as 'raspy', but is also related to 'pony' as it sounds like 'horse'. \n",
    "\n",
    "___\n",
    "\n",
    "In order to test this, we will do the following:\n",
    "\n",
    "* Step 1: Use Synset to list synonyms of tokens\n",
    "* Step 2: Find matching similar sounding words in Synsets within the sentence\n",
    "* Step 3: \n",
    "\n",
    "Some inspirations:\n",
    "* https://stackabuse.com/phonetic-similarity-of-words-a-vectorized-approach-in-python/\n",
    "* https://pypi.org/project/phonetics/#usage\n",
    "* https://pypi.org/project/jellyfish/\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Import/Download relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phonetics\n",
    "import jellyfish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the library's differeny phonetic functions with two similar sounding words 'horse' and 'hoarse', and observing the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horse', 'hoarse']\n",
      "soundex: h0620 h0620 \n",
      "nysiis: HA HA \n",
      "metaphone: HRS HRS \n",
      "dmetaphone: ('HRS', '') ('HRS', '') \n",
      "match_rating_codex: HRS HRS \n"
     ]
    }
   ],
   "source": [
    "test_words = ['horse', 'hoarse']\n",
    "print(test_words)\n",
    "def print_phonetic_index(test_words):\n",
    "    functions = (phonetics.soundex, phonetics.nysiis, phonetics.metaphone, phonetics.dmetaphone, jellyfish.match_rating_codex)\n",
    "    for func in functions:\n",
    "        print(f'{func.__name__}: ' , end='')\n",
    "        for word in test_words:\n",
    "            code = func(word)\n",
    "            print(str(code) + ' ', end='')\n",
    "        print()\n",
    "print_phonetic_index(test_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with the words 'horse' and 'haorse' gave identical phonetic indexes from different packages. Let's try this with another set of words!\n",
    "Pun examples:\n",
    "* A harp which sounds too good to be true is probably a lyre. (lie)\n",
    "* Religious lions get down to their knees to prey. (pray)\n",
    "* A big computerized dog needs a megabyte. (mega bite)\n",
    "* Lions eat their prey fresh and roar. (raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soundex: l060 l000 p600 p600 r060 r000 \n",
      "nysiis: LA LA PA PA RA RA \n",
      "metaphone: LR L PR PR RR R \n",
      "dmetaphone: ('LR', '') ('L', '') ('PR', '') ('PR', '') ('RR', '') ('R', 'RF') \n",
      "match_rating_codex: LYR L PRY PRY RR RW \n"
     ]
    }
   ],
   "source": [
    "test_words_2 = ['lyre', 'lie', 'prey', 'pray', 'roar', 'raw']\n",
    "print_phonetic_index(test_words_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dappity dap.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
